# Imports

import os
import torch
import torch.nn as nn
import torchvision
import numpy as np
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision.ops import MultiScaleRoIAlign
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
import torchvision.transforms as T

# Dataset (Synthetic Bounding Boxes)
class TomatoDetectionDataset(Dataset):
    def __init__(self, root, transforms=None):
        self.root = root
        self.transforms = transforms
        self.classes = sorted(os.listdir(root))
        self.class_to_idx = {c: i+1 for i,c in enumerate(self.classes)}

        self.samples = []
        for cls in self.classes:
            for img in os.listdir(os.path.join(root, cls)):
                self.samples.append((os.path.join(root, cls, img), cls))

    def __getitem__(self, idx):
        img_path, cls = self.samples[idx]
        img = Image.open(img_path).convert("RGB")

        w, h = img.size
        boxes = torch.tensor([[0, 0, w, h]], dtype=torch.float32)
        labels = torch.tensor([self.class_to_idx[cls]])

        target = {
            "boxes": boxes,
            "labels": labels,
            "image_id": torch.tensor([idx]),
            "area": torch.tensor([w*h]),
            "iscrowd": torch.zeros((1,), dtype=torch.int64)
        }

        if self.transforms:
            img = self.transforms(img)

        return img, target

    def __len__(self):
        return len(self.samples)

# Transforms
def get_transform(train=True):
    t = []
    t.append(T.Resize((256,256)))
    t.append(T.ToTensor())
    if train:
        t.append(T.RandomHorizontalFlip(0.5))
        t.append(T.RandomRotation(15))
    return T.Compose(t)

# Custom Backbone
class SimpleCNNBackbone(nn.Module):
    def __init__(self):
        super().__init__()
        self.body = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU()
        )
        self.out_channels = 128

    def forward(self, x):
        return self.body(x)

# Faster R-CNN
def build_model(num_classes):
    backbone = SimpleCNNBackbone()

    anchor_generator = AnchorGenerator(
        sizes=((32, 64, 128),),
        aspect_ratios=((0.5, 1.0, 2.0),)
    )

    roi_pooler = MultiScaleRoIAlign(
        featmap_names=['0'],
        output_size=7,
        sampling_ratio=2
    )

    model = FasterRCNN(
        backbone,
        num_classes=num_classes,
        rpn_anchor_generator=anchor_generator,
        box_roi_pool=roi_pooler
    )
    return model

# DataLoaders
def collate_fn(batch):
    return tuple(zip(*batch))

train_ds = TomatoDetectionDataset(
    "/kaggle/input/tomatoleaf/tomato/train",
    transforms=get_transform(True)
)

val_ds = TomatoDetectionDataset(
    "/kaggle/input/tomatoleaf/tomato/val",
    transforms=get_transform(False)
)

train_dl = DataLoader(train_ds, batch_size=6, shuffle=True, collate_fn=collate_fn)
val_dl = DataLoader(val_ds, batch_size=6, shuffle=False, collate_fn=collate_fn)

# Training Setup (Hyperparameter Tuned)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = len(train_ds.classes) + 1
model = build_model(num_classes).to(device)

optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=0.0005,
    weight_decay=1e-4
)

# Training Loop
def train_epoch(model, loader):
    model.train()
    total_loss = 0

    for imgs, targets in loader:
        imgs = [img.to(device) for img in imgs]
        targets = [{k:v.to(device) for k,v in t.items()} for t in targets]

        loss_dict = model(imgs, targets)
        loss = sum(loss_dict.values())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    return total_loss / len(loader)

# Evaluation (Classification Accuracy)
def evaluate(model, loader):
    model.eval()
    correct = total = 0

    with torch.no_grad():
        for imgs, targets in loader:
            imgs = [img.to(device) for img in imgs]
            outputs = model(imgs)

            for o, t in zip(outputs, targets):
                if len(o["labels"]) > 0:
                    pred = o["labels"][0].item()
                    gt = t["labels"].item()
                    if pred == gt:
                        correct += 1
                total += 1

    return correct / total

# Run Training
for epoch in range(20):
    loss = train_epoch(model, train_dl)
    acc = evaluate(model, val_dl)
    print(f"Epoch {epoch+1}: Loss={loss:.4f}, Acc={acc*100:.2f}%")
