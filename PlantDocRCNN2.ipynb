# ===============================
# ORIGINAL R-CNN FROM SCRATCH
# ===============================

import os
import xml.etree.ElementTree as ET
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
import joblib

# Selective Search implementation
import sys
sys.path.append('/kaggle/input/selectivesearch/')
# Note: You'll need to install selective-search library or implement it manually

# ===============================
# CONFIG
# ===============================
DATA_ROOT = "/kaggle/input/plantdoc-dataset"
CLASSES = sorted([f for f in os.listdir(DATA_ROOT) 
                 if os.path.isdir(os.path.join(DATA_ROOT, f)) and f != 'test'])
CLASSES = ["background"] + CLASSES
CLASS_TO_IDX = {c: i for i, c in enumerate(CLASSES)}
NUM_CLASSES = len(CLASSES) - 1  # Excluding background for SVM

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
EPOCHS = 100
BATCH_SIZE = 64
LR = 0.001

# AlexNet-like feature extractor
class RCNNFeatureExtractor(nn.Module):
    def __init__(self):
        super(RCNNFeatureExtractor, self).__init__()
        self.features = nn.Sequential(
            # Conv1
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv2
            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),
            nn.ReLU(inplace=True),
            nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv3
            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv4
            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv5
            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            
            nn.Dropout(p=0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
        )
        
        # Separate heads for classification and regression
        self.cls_head = nn.Linear(4096, NUM_CLASSES)
        self.reg_head = nn.Linear(4096, NUM_CLASSES * 4)  # 4 coordinates per class
        
    def forward(self, x, return_features=False):
        x = self.features(x)
        x = torch.flatten(x, 1)
        features = self.classifier(x)
        
        if return_features:
            return features
        
        cls_scores = self.cls_head(features)
        bbox_deltas = self.reg_head(features)
        
        return cls_scores, bbox_deltas

# ===============================
# R-CNN PIPELINE
# ===============================
class RCNN:
    def __init__(self):
        self.feature_extractor = RCNNFeatureExtractor().to(DEVICE)
        self.svms = [LinearSVC(C=1.0) for _ in range(NUM_CLASSES)]
        self.bbox_regressors = [None for _ in range(NUM_CLASSES)]
        self.scalers = [StandardScaler() for _ in range(NUM_CLASSES)]
        
    def selective_search(self, image, mode='fast'):
        """
        Simplified Selective Search implementation
        In practice, use opencv's selective search:
        cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
        """
        # This is a placeholder - implement proper selective search
        import random
        h, w = image.shape[:2]
        proposals = []
        
        # Generate random proposals (simplified)
        for _ in range(2000):
            width = random.randint(int(w*0.1), int(w*0.5))
            height = random.randint(int(h*0.1), int(h*0.5))
            x = random.randint(0, w - width)
            y = random.randint(0, h - height)
            proposals.append([x, y, x+width, y+height])
        
        return proposals[:2000]  # Return top 2000
    
    def extract_region_features(self, image, regions):
        """Extract features for each region proposal"""
        features = []
        transforms = T.Compose([
            T.Resize((227, 227)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        for x1, y1, x2, y2 in regions:
            region = image.crop((x1, y1, x2, y2))
            region_tensor = transforms(region).unsqueeze(0).to(DEVICE)
            
            with torch.no_grad():
                region_features = self.feature_extractor(region_tensor, return_features=True)
                features.append(region_features.cpu().numpy().flatten())
        
        return np.array(features)
    
    def compute_iou(self, box1, box2):
        """Compute Intersection over Union"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])
        
        intersection = max(0, x2 - x1) * max(0, y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0
    
    def train_svm(self, features, labels, class_idx):
        """Train SVM for a specific class"""
        # Create binary labels for this class
        binary_labels = (labels == class_idx).astype(int)
        
        if len(np.unique(binary_labels)) > 1:
            # Scale features
            scaled_features = self.scalers[class_idx].fit_transform(features)
            self.svms[class_idx].fit(scaled_features, binary_labels)
            return True
        return False
    
    def train_bbox_regressor(self, features, gt_boxes, pred_boxes, labels, class_idx):
        """Train bounding box regressor for a specific class"""
        class_mask = labels == class_idx
        if np.sum(class_mask) < 10:  # Need enough samples
            return False
        
        class_features = features[class_mask]
        class_gt = gt_boxes[class_mask]
        class_pred = pred_boxes[class_mask]
        
        # Compute targets: Δx, Δy, Δw, Δh
        targets = np.zeros((len(class_gt), 4))
        for i in range(len(class_gt)):
            gt = class_gt[i]
            pred = class_pred[i]
            
            # Center coordinates and dimensions
            gt_cx = (gt[0] + gt[2]) / 2
            gt_cy = (gt[1] + gt[3]) / 2
            gt_w = gt[2] - gt[0]
            gt_h = gt[3] - gt[1]
            
            pred_cx = (pred[0] + pred[2]) / 2
            pred_cy = (pred[1] + pred[3]) / 2
            pred_w = pred[2] - pred[0]
            pred_h = pred[3] - pred[1]
            
            targets[i, 0] = (gt_cx - pred_cx) / pred_w  # Δx
            targets[i, 1] = (gt_cy - pred_cy) / pred_h  # Δy
            targets[i, 2] = np.log(gt_w / pred_w)      # Δw
            targets[i, 3] = np.log(gt_h / pred_h)      # Δh
        
        # Train ridge regression
        from sklearn.linear_model import Ridge
        self.bbox_regressors[class_idx] = Ridge(alpha=1.0)
        self.bbox_regressors[class_idx].fit(class_features, targets)
        
        return True
    
    def train(self, dataset, epochs=10):
        """R-CNN training pipeline"""
        print("Training R-CNN...")
        
        # Step 1: Fine-tune CNN on warped region proposals
        print("Step 1: Fine-tuning CNN...")
        self.fine_tune_cnn(dataset)
        
        # Step 2: Extract features and train SVMs
        print("Step 2: Training SVMs...")
        all_features = []
        all_labels = []
        all_gt_boxes = []
        all_pred_boxes = []
        
        for idx in range(min(1000, len(dataset))):  # Use subset for training
            img, target = dataset[idx]
            gt_boxes = target['boxes'].numpy()
            gt_labels = target['labels'].numpy()
            
            # Get region proposals
            proposals = self.selective_search(np.array(img))
            
            # Match proposals to GT boxes
            positive_samples = {c: [] for c in range(NUM_CLASSES)}
            negative_samples = {c: [] for c in range(NUM_CLASSES)}
            
            for proposal in proposals:
                best_iou = 0
                best_class = -1
                
                for gt_box, gt_label in zip(gt_boxes, gt_labels):
                    iou = self.compute_iou(proposal, gt_box)
                    if iou > best_iou:
                        best_iou = iou
                        best_class = gt_label - 1  # Adjust for background
                
                if best_iou >= 0.5 and best_class >= 0:
                    positive_samples[best_class].append(proposal)
                elif best_iou < 0.3:
                    for c in range(NUM_CLASSES):
                        negative_samples[c].append(proposal)
            
            # Extract features for positive samples
            for c in range(NUM_CLASSES):
                if len(positive_samples[c]) > 0:
                    features = self.extract_region_features(img, positive_samples[c][:10])
                    all_features.extend(features)
                    all_labels.extend([c] * len(features))
                    all_gt_boxes.extend([gt_boxes[0]] * len(features))  # Simplified
                    all_pred_boxes.extend(positive_samples[c][:10])
        
        all_features = np.array(all_features)
        all_labels = np.array(all_labels)
        
        # Train SVMs for each class
        for c in range(NUM_CLASSES):
            print(f"Training SVM for class {CLASSES[c+1]}...")
            self.train_svm(all_features, all_labels, c)
        
        # Step 3: Train bounding box regressors
        print("Step 3: Training bounding box regressors...")
        for c in range(NUM_CLASSES):
            if self.train_bbox_regressor(all_features, 
                                        np.array(all_gt_boxes),
                                        np.array(all_pred_boxes),
                                        all_labels, c):
                print(f"  Trained regressor for {CLASSES[c+1]}")
        
        print("Training complete!")
    
    def fine_tune_cnn(self, dataset, num_epochs=20):
        """Fine-tune CNN on warped region proposals"""
        optimizer = optim.SGD(self.feature_extractor.parameters(), 
                            lr=LR, momentum=0.9, weight_decay=0.0005)
        criterion = nn.CrossEntropyLoss()
        
        dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
        
        for epoch in range(num_epochs):
            self.feature_extractor.train()
            total_loss = 0
            
            for images, targets in dataloader:
                batch_features = []
                batch_labels = []
                
                for img, target in zip(images, targets):
                    # Simple data augmentation: random crops
                    transforms = T.Compose([
                        T.RandomResizedCrop(227, scale=(0.8, 1.0)),
                        T.ToTensor(),
                        T.Normalize(mean=[0.485, 0.456, 0.406], 
                                   std=[0.229, 0.224, 0.225])
                    ])
                    
                    # Use first object as label (simplified)
                    if len(target['labels']) > 0:
                        warped = transforms(img)
                        batch_features.append(warped)
                        batch_labels.append(target['labels'][0] - 1)  # Exclude background
                
                if len(batch_features) > 0:
                    batch_features = torch.stack(batch_features).to(DEVICE)
                    batch_labels = torch.tensor(batch_labels).to(DEVICE)
                    
                    optimizer.zero_grad()
                    cls_scores, _ = self.feature_extractor(batch_features)
                    loss = criterion(cls_scores, batch_labels)
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
            
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}")
    
    def predict(self, image):
        """R-CNN inference pipeline"""
        # Get region proposals
        proposals = self.selective_search(np.array(image))
        
        # Extract features
        features = self.extract_region_features(image, proposals)
        
        detections = []
        
        for i, (proposal, feature) in enumerate(zip(proposals, features)):
            scores = []
            
            # Score with each SVM
            for c in range(NUM_CLASSES):
                if self.svms[c] is not None:
                    scaled_feature = self.scalers[c].transform([feature])
                    score = self.svms[c].decision_function(scaled_feature)[0]
                    scores.append(score)
                else:
                    scores.append(-np.inf)
            
            # Get best class
            best_class = np.argmax(scores)
            best_score = scores[best_class]
            
            if best_score > 0:  # Positive detection
                # Apply bounding box regression
                if self.bbox_regressors[best_class] is not None:
                    bbox_delta = self.bbox_regressors[best_class].predict([feature])[0]
                    
                    # Apply regression
                    x1, y1, x2, y2 = proposal
                    w = x2 - x1
                    h = y2 - y1
                    cx = x1 + w/2
                    cy = y1 + h/2
                    
                    cx_new = cx + bbox_delta[0] * w
                    cy_new = cy + bbox_delta[1] * h
                    w_new = w * np.exp(bbox_delta[2])
                    h_new = h * np.exp(bbox_delta[3])
                    
                    proposal = [
                        cx_new - w_new/2,
                        cy_new - h_new/2,
                        cx_new + w_new/2,
                        cy_new + h_new/2
                    ]
                
                detections.append({
                    'box': proposal,
                    'class': best_class + 1,  # Add background offset
                    'score': best_score
                })
        
        # Non-maximum suppression
        detections = self.nms(detections, iou_threshold=0.3)
        
        return detections
    
    def nms(self, detections, iou_threshold=0.3):
        """Non-maximum suppression"""
        if len(detections) == 0:
            return []
        
        # Sort by score
        detections.sort(key=lambda x: x['score'], reverse=True)
        
        keep = []
        while detections:
            best = detections.pop(0)
            keep.append(best)
            
            # Remove overlapping detections
            detections = [d for d in detections 
                         if self.compute_iou(best['box'], d['box']) < iou_threshold]
        
        return keep
    
    def evaluate(self, dataset):
        """Evaluate R-CNN"""
        all_preds = []
        all_labels = []
        
        for idx in range(min(200, len(dataset))):  # Evaluate on subset
            img, target = dataset[idx]
            
            detections = self.predict(img)
            gt_labels = target['labels'].numpy()
            
            if len(detections) > 0 and len(gt_labels) > 0:
                # Use top detection
                all_preds.append(detections[0]['class'])
                all_labels.append(gt_labels[0])
        
        from sklearn.metrics import accuracy_score
        acc = accuracy_score(all_labels, all_preds) if len(all_labels) > 0 else 0
        return acc

# ===============================
# MAIN TRAINING
# ===============================
if __name__ == "__main__":
    # Create dataset (simplified version)
    class SimpleDataset(Dataset):
        def __init__(self, data_root, max_samples=100):
            self.samples = []
            class_folders = [f for f in os.listdir(data_root) 
                           if os.path.isdir(os.path.join(data_root, f))]
            
            for class_idx, class_name in enumerate(class_folders, 1):
                class_path = os.path.join(data_root, class_name)
                images = [f for f in os.listdir(class_path) 
                         if f.endswith('.jpg')][:max_samples//len(class_folders)]
                
                for img_name in images:
                    img_path = os.path.join(class_path, img_name)
                    self.samples.append((img_path, class_idx))
        
        def __len__(self):
            return len(self.samples)
        
        def __getitem__(self, idx):
            img_path, label = self.samples[idx]
            img = Image.open(img_path).convert('RGB')
            
            # Create dummy bounding box (simplified)
            w, h = img.size
            boxes = torch.tensor([[w*0.2, h*0.2, w*0.8, h*0.8]], dtype=torch.float32)
            labels = torch.tensor([label], dtype=torch.int64)
            
            target = {
                'boxes': boxes,
                'labels': labels,
                'image_id': torch.tensor([idx]),
                'area': (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),
                'iscrowd': torch.zeros((len(boxes),), dtype=torch.int64)
            }
            
            return img, target
    
    # Create and train R-CNN
    dataset = SimpleDataset(DATA_ROOT, max_samples=500)
    rcnn = RCNN()
    
    print(f"Training on {len(dataset)} samples...")
    rcnn.train(dataset, epochs=20)
    
    # Evaluate
    accuracy = rcnn.evaluate(dataset)
    print(f"\nFinal Accuracy: {accuracy*100:.2f}%")
    
    if accuracy >= 0.75:
        print("✓ Requirement met: Accuracy ≥ 75%")
    else:
        print("✗ Requirement not met: Accuracy < 75%")
        print("Consider:")
        print("1. Increase training data")
        print("2. Use proper selective search implementation")
        print("3. Add data augmentation")
        print("4. Tune hyperparameters")
